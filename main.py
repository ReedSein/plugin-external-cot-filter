import os
import re
from datetime import datetime

from astrbot import logger
from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register
# å…³é”®å¯¼å…¥ï¼šæˆ‘ä»¬éœ€è¦ LLMResponse ç±»å‹æ¥ç›´æ¥ä¿®æ”¹æ¨¡å‹å›å¤
from astrbot.api.provider import LLMResponse

# --- æ—¥å¿—è®°å½•éƒ¨åˆ† (ä¸åŸä»£ç ç›¸åŒ) ---
# æ³¨æ„ï¼šå»ºè®®å°† LOG_DIR é…ç½®åŒ–ï¼Œè€Œä¸æ˜¯ç¡¬ç¼–ç 
LOG_DIR = r"logs"

def log_thought(content: str):
    """å°†æ€è€ƒå†…å®¹å†™å…¥ç‹¬ç«‹çš„æ—¥å¿—æ–‡ä»¶"""
    if not content:
        return
    try:
        if not os.path.exists(LOG_DIR):
            os.makedirs(LOG_DIR)
        now = datetime.now()
        log_file = os.path.join(LOG_DIR, f"{now.strftime('%Y-%m-%d')}_thought.log")
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(f"[{now.strftime('%Y-%m-%d %H:%M:%S')}] {content}\n\n") # å¢åŠ æ¢è¡Œä»¥åˆ†éš”æ—¥å¿—
    except Exception as e:
        logger.error(f"å†™å…¥æ€è€ƒæ—¥å¿—æ—¶å‘ç”Ÿé”™è¯¯: {e}")

# --- æ’ä»¶æ ¸å¿ƒä»£ç  (ä¿®æ”¹å) ---

@register("astrbot_plugin_external_cot_filter", "RIN", "è¿‡æ»¤æˆ–æ˜¾ç¤ºå¤–éƒ¨æ€ç»´é“¾", "2.0.0")
class ExternalCoTFilter(Star):
    """
    ä¸€ä¸ªç”¨äºå¤„ç†å¤–éƒ¨æ€ç»´é“¾ï¼ˆCoTï¼‰çš„æ’ä»¶ã€‚
    å®ƒç›´æ¥åœ¨LLMå“åº”å±‚è¿›è¡Œæ“ä½œï¼Œå¯ä»¥é…ç½®ä¸ºï¼š
    1. è¿‡æ»¤å¹¶è®°å½•æ€ç»´é“¾ï¼Œä»…æ˜¾ç¤ºæœ€ç»ˆå›å¤ã€‚
    2. å°†æ€ç»´é“¾ä¸æœ€ç»ˆå›å¤ä¸€èµ·æ ¼å¼åŒ–æ˜¾ç¤ºã€‚
    """

    # ç­–ç•¥1ï¼šåŸºäºæœ€ç»ˆå›å¤æ ‡è®°çš„æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œåˆ†å‰² (é«˜ä¼˜å…ˆçº§)
    FINAL_REPLY_PATTERN = re.compile(r"æœ€ç»ˆçš„ç½—èå›å¤[:ï¼š]?\s*", re.IGNORECASE)

    # ç­–ç•¥2ï¼šåŸºäºXMLæ ‡ç­¾è¿›è¡Œè¿‡æ»¤ (å½“ç­–ç•¥1å¤±è´¥æ—¶ä½¿ç”¨)
    THOUGHT_TAG_PATTERN = re.compile(
        r'<(?P<tag>think|thinking|disclaimer|ç½—èå†…å¿ƒOS)>(?P<content>.*?)</(?P=tag)>',
        re.DOTALL | re.IGNORECASE
    )
    # ç­–ç•¥3ï¼šåŸºäºæ— æ ‡ç­¾çš„ "Thinking:" å…³é”®è¯è¿›è¡Œè¿‡æ»¤
    UNBOUND_THINKING_PATTERN = re.compile(r'Thinking:\s*.*', re.DOTALL | re.IGNORECASE)

    def __init__(self, context: Context):
        super().__init__(context)
        # ä»é…ç½®ä¸­è¯»å–æ˜¯å¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼Œé»˜è®¤ä¸ºFalse (å³è¿‡æ»¤æ‰)
        self.display_cot_text = (
            self.context.get_config()
            .get("provider_settings", {})
            .get("display_cot_text", False)
        )
        logger.info(f"å¤–éƒ¨æ€ç»´é“¾æ’ä»¶åŠ è½½ï¼Œæ˜¾ç¤ºæ¨¡å¼: {'å¼€å¯' if self.display_cot_text else 'å…³é—­'}")
        
        
    FILTERED_KEYWORDS = [
        "å“¦ï¼Ÿ","å‘µå‘µ",
        # ä»¥åå¯åœ¨æ­¤æ·»åŠ æ›´å¤šè¯
    ]

    @staticmethod
    def filter_keywords(text: str) -> str:
        """è¿‡æ»¤æ‰æŒ‡å®šå…³é”®è¯"""
        for kw in ExternalCoTFilter.FILTERED_KEYWORDS:
            text = text.replace(kw, "")
        return text


    @filter.on_llm_response()
    async def process_llm_response(self, event: AstrMessageEvent, response: LLMResponse):
        # å¦‚æœæ²¡æœ‰å›å¤å†…å®¹ï¼Œåˆ™ç›´æ¥è¿”å›
        if not response or not response.completion_text:
            return

        original_text = response.completion_text
        thought_part = ""
        reply_part = ""

        # --- ç­–ç•¥1ï¼šå°è¯•ä½¿ç”¨ "æœ€ç»ˆçš„è’™å¤šå›å¤" æ ‡è®°è¿›è¡Œåˆ†å‰² ---
        parts = self.FINAL_REPLY_PATTERN.split(original_text, 1)
        if len(parts) > 1:
            thought_part = parts[0].strip()
            reply_part = parts[1].strip()
            logger.debug(f"Thought: {thought_part}")
        else:
            # --- ç­–ç•¥2 & 3ï¼šå¦‚æœç­–ç•¥1å¤±è´¥ï¼Œåˆ™å›é€€åˆ°æ ‡ç­¾å’Œå…³é”®è¯è¿‡æ»¤ ---
            
            # å…ˆæ”¶é›†æ‰€æœ‰æ€è€ƒå†…å®¹
            thoughts_found = []
            temp_text = original_text

            # åŒ¹é…å¸¦æ ‡ç­¾çš„æ€è€ƒ
            for match in self.THOUGHT_TAG_PATTERN.finditer(temp_text):
                thoughts_found.append(match.group('content').strip())
            
            # åŒ¹é…æ— æ ‡ç­¾çš„ "Thinking:"
            for match in self.UNBOUND_THINKING_PATTERN.finditer(temp_text):
                # é¿å…é‡å¤è®°å½•å·²åœ¨æ ‡ç­¾å†…çš„ "Thinking:"
                if not self.THOUGHT_TAG_PATTERN.search(match.group(0)):
                    thoughts_found.append(match.group(0).strip())

            if thoughts_found:
                thought_part = "\n".join(thoughts_found)
                
                # ä»åŸæ–‡ä¸­ç§»é™¤æ‰€æœ‰æ€è€ƒéƒ¨åˆ†ï¼Œå¾—åˆ°çº¯å‡€çš„å›å¤
                cleaned_text = self.THOUGHT_TAG_PATTERN.sub("", original_text)
                cleaned_text = self.UNBOUND_THINKING_PATTERN.sub("", cleaned_text)
                reply_part = cleaned_text.strip()
                
                logger.debug(f"é€šè¿‡æ ‡ç­¾/å…³é”®è¯åˆ†ç¦»å‡ºæ€è€ƒå†…å®¹: {thought_part}")
            else:
                # å¦‚æœæ²¡æœ‰ä»»ä½•æ€è€ƒæ ‡è®°ï¼Œåˆ™è®¤ä¸ºå…¨éƒ¨éƒ½æ˜¯å›å¤å†…å®¹
                reply_part = original_text.strip()

        # --- æ—¥å¿—è®°å½•ä¸æœ€ç»ˆæ–‡æœ¬ç»„è£… ---

        # æ— è®ºæ˜¯å¦æ˜¾ç¤ºï¼Œéƒ½è®°å½•æ€è€ƒè¿‡ç¨‹
        if thought_part:
            log_thought(thought_part)
            
        # å…³é”®è¯è¿‡æ»¤ï¼ˆä»…å¯¹æœ€ç»ˆå›å¤éƒ¨åˆ†å¤„ç†ï¼‰
        reply_part = self.filter_keywords(reply_part)

        # æ ¹æ®é…ç½®å†³å®šæœ€ç»ˆè¾“å‡º
        if self.display_cot_text and thought_part:
            # æ ¼å¼åŒ–æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆå›å¤
            response.completion_text = f"ğŸ¤” æ€è€ƒè¿‡ç¨‹ï¼š\n{thought_part}\n\n---\n\n{reply_part}"
        else:
            # ä»…æ˜¾ç¤ºæœ€ç»ˆå›å¤
            response.completion_text = reply_part